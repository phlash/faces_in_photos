#! /usr/bin/env python3
#
# Scheduled task (use the cron Luke) to find all new / moved / removed image files since last run, and:
# 1- update database with moved / removed images, write list of moved / removed files and removed faces
# 2- detect faces in new images, classify against existing groups, write list of new labelled and unlabelled faces
#
# We use a mark/release strategy to find all file changes, by re-hashing the search tree(s), and noting all
# hashes we already have, then anything we didn't find has been removed, some files may have moved (check paths)
#
# New hashes are candidate new images, so try loading and detecting faces..

import os, sys, syslog, hashlib, numpy, pickle, math, resource, traceback
import sqlite3
from PIL import Image, ExifTags
import face_recognition
import tflit

# Well-known configuration file location
cfgfile = '/etc/default/face_scanner'

# Default configuration values
cfg = {}
cfg['dbfile'] = '/etc/face_scanner.db'
cfg['verbose'] = False
cfg['syslog'] = True
cfg['report_count'] = 1000
cfg['threshold'] = 0.3
cfg['unknown'] = '_Unknown_'
cfg['tf_model'] = 'deeplabv3_257_mv_gpu.tflite'

# Apply config overrides (if any)
if os.path.isfile(cfgfile):
    with open(cfgfile, 'rt') as c:
        for l in c:
            if l.startswith('#') or ('=' not in l):
                continue
            k,v = l.partition('=')[::2]
            cfg[k.strip()] = v.strip()

if len(sys.argv)>1:
    for l in sys.argv[1:]:
        k,v = l.partition('=')[::2]
        cfg[k.strip()] = v.strip()

# Logger
if cfg['syslog']:
    syslog.openlog('face_scanner', syslog.LOG_PID)

def logmsg(msg):
    if cfg['verbose']:
        print(msg)
    if cfg['syslog']:
        syslog.syslog(syslog.LOG_INFO, msg)

def logerr(msg):
    print(msg)
    if cfg['syslog']:
        syslog.syslog(syslog.LOG_ERR, msg)

logmsg("starting..")

# Tensorflow filter
labels = [ "background", "aeroplane", "bicycle", "bird", "boat", "bottle", "bus", "car", "cat", "chair", "cow", "dining table", "dog", "horse", "motorbike", "person", "potted plant", "sheep", "sofa", "train", "tv" ]
ipers = labels.index("person")
def tf_model():
    return tflit.Model(cfg['tf_model'])

def tf_filter(pil, model):
    # resize to model
    h = model.input_details[0]['shape'][1]
    w = model.input_details[0]['shape'][2]
    img = pil.resize((w, h))
    # wrap in an outer array for TF
    datain = numpy.expand_dims(img, axis=0)
    # map 0-255 rgb into -1>1 floats
    datain = (numpy.float32(datain) - 127.5)/127.5
    # set as input to tf
    model.interpreter.set_tensor(model.input_details[0]['index'], datain)
    # run the model
    model.interpreter.invoke()
    # grab output
    dataout = model.interpreter.get_tensor(model.output_details[0]['index'])
    # reduce from nested array (inverse of above)
    res = numpy.squeeze(dataout)
    # walk output pixels, if any are most likely a person, return True
    for y in range(0,len(res)):
        for x in range(0,len(res[y])):
            maxv = res[y][x][0]
            mpos = 0
            for i in range(1,len(res[y][x])):
                if res[y][x][i]>maxv:
                    maxv = res[y][x][i]
                    mpos = i
            if mpos==ipers:
                return True
    return False

# Open the DB
if not os.path.isfile(cfg['dbfile']):
    logerr("No such file: {}".format(cfg['dbfile']))
    sys.exit(1)
db = sqlite3.connect(cfg['dbfile'])
# do NOT convert to/from unicode by default
db.text_factory = bytes
# our custom unicode convertor for row data
def rowconv(cur, row):
    # convert bytes => str unless the column name starts with 'pickle' (yuk!)
    return [(v.decode('utf-8') if (isinstance(v,bytes) and not cur.description[i][0].startswith('pickle')) else v) for i,v in enumerate(row)]
db.row_factory = rowconv
cur = db.cursor()
cur.execute('PRAGMA foreign_keys = ON')

# Apply config overrides from DB (if any)
cur.execute('SELECT key, value from face_scanner_config')
for row in cur:
    cfg[row[0].strip()] = row[1].strip()

# Dump final config
if cfg['verbose']:
    for k in cfg:
        logmsg("config: {} = {}".format(k, cfg[k]))

# Load Tensorflow model
logmsg('loading tensorflow model: {}'.format(cfg['tf_model']))
model = tf_model()

# Load existing hashes into forward and reverse dictionaries
logmsg("loading existing hashes & candidates..")
htp = {}
pth = {}
cur.execute('SELECT path, size, hash from file_paths')
for row in cur:
    if row[2] in htp:
        p = htp[row[2]]
    else:
        p = []
        htp[row[2]] = p
    p.append((row[0],row[1]))
    pth[row[0]] = (row[1],row[2])

# Candidate new images
candidates = {}
cur.execute('SELECT path, hash from file_candidates')
for row in cur:
    candidates[row[1]] = row[0]

logmsg("loaded {} hashes for {} files, {} candidates".format(len(htp), len(pth), len(candidates)))

# Start hashing files in search tree(s)..
def hashfile(cand):
    sha256 = hashlib.sha256()
    with open(cand, 'rb') as f:
        while True:
            d = f.read(1048576)       # 1Mi block size, might need tuning..
            if not d:
                break
            sha256.update(d)
    return sha256.hexdigest()

# Source paths to search
src = []
cur.execute('SELECT path from source_paths')
for row in cur:
    src.append(row[0])
if 'source_path' in cfg:
    src = []
    src.append(cfg['source_path'])
cnt = 0
opt = 0
knw = 0
mov = 0
can = 0
dup = 0
dirty = False
for path in src:
    logmsg("walking tree from {}".format(path))
    for root, subs, files in os.walk(path):
        for f in files:
            cnt += 1
            cand = os.path.join(root, f)
            # special check for our own database file.. ignore it!
            if cfg['dbfile'] == cand:
                continue
            size = None
            try:
                size = os.stat(cand).st_size
            except Exception as e:
                logmsg("failed to stat {}: {}".format(cand, e))
                continue
            # Optimisation, skip hashing if path and size match, assume we have it
            # NB: We keep file info on everything, incluing non-image files, as this
            # allows us to skip them next time
            if cand in pth and (pth[cand][0] == size):
                opt += 1
                hash = pth[cand][1]
            else:
                hash = hashfile(cand)

            if hash in htp:         # Known hash
                knw += 1
                pl = htp[hash]
                if cand in pth:
                    pth.pop(cand)       # Known hash, in known location, ignore it.
                    pl.remove((cand,size))
                else:
                    mov += 1            # Known hash in new location, add to db.
                    cur.execute('INSERT INTO file_paths (path,size,hash) values (?,?,?)', (cand,size,hash))  
                    dirty = True
                    pl.append((cand,size))

            else:                   # Unknown hash
                can += 1
                if hash not in candidates:
                    candidates[hash] = cand
                    cur.execute('INSERT OR IGNORE INTO file_hashes (hash) values (?)', (hash,))
                    cur.execute('INSERT OR IGNORE INTO file_candidates (path,hash) values (?,?)', (cand,hash))
                else:
                    dup += 1
                cur.execute('INSERT INTO file_paths (path,size,hash) values (?,?,?)', (cand,size,hash))
                dirty = True
            if (cnt % int(cfg['report_count'])) == 0:
                logmsg("{} files hashed, {} optimised, {} known, {} new path, {} candidates, {} duplicates ..".format(cnt, opt, knw, mov, can, dup))
            if dirty and (cnt % 100) == 0:
                db.commit()
                dirty = False
if dirty:
    db.commit()
    dirty = False
logmsg("hashing complete after {} files".format(cnt))

# Any remaining paths in the path to hash table are unvisited files, so no longer exist
# print report on files and faces being removed, then remove them
logmsg("{} files no longer present, cleaning up database".format(len(pth)))
print("File -> [face(s)] removed in this run:")
for path in pth:
    cur.execute('SELECT l.label from file_paths as p, face_labels as l, face_groups as g, face_data as d where' +
            ' p.path = ? and p.hash = d.hash and d.grp = g.grp and g.label = l.label', (path,))
    nams = [x[0] for x in cur]
    print("\t{} -> {}".format(path, nams))
    cur.execute('DELETE FROM file_paths where path = ?', (path,))
    dirty = True
if dirty:
    db.commit()
    dirty = False

# Finally - having reduced our workload as as far as possible, the fun stuff - face detection & recognition!
# Load the face vector weights
cur.execute('SELECT pickled from face_weights')
# Oh the joy of decoding Python2 pickled numpy arrays:
# https://docs.python.org/3/library/pickle.html#pickle.Unpickler
weights = pickle.loads(cur.fetchone()[0],encoding='latin-1')

# Load the existing faces and average each group if required
logmsg("loading groups and averaging faces..")
groups = {}
fcs = 0
cur.execute('SELECT grp, pickled, label from face_groups')
for row in cur:
    grp = row[0]
    lab = row[2]
    avg = []
    # Use the average, or..
    if row[1]:
        avg = pickle.loads(row[1],encoding='latin-1')
    # Generate from the group content
    else:
        cnt = 1.0
        c2 = db.cursor()
        c2.execute('SELECT pickled from face_data where grp = ?', (grp,))
        for r2 in c2:
            fcs += 1
            enc = pickle.loads(r2[0],encoding='latin-1')
            if len(avg) == 0:
                avg = enc
                continue
            for i in range(0,len(enc)):
                avg[i] = (cnt-1)/cnt * avg[i] + 1/cnt * enc[i]
            cnt += 1.0
        c2.execute('UPDATE face_groups set pickled = ? where grp = ?', (pickle.dumps(avg), grp))
        dirty = True
        logmsg("{}: averaged faces for label {}".format(grp, lab))
    if len(avg)<=0:
        logerr("group {} has no faces".format(grp))
    groups[grp] = (avg,lab)
if dirty:
    db.commit()
    dirty = False
logmsg("{} groups from {} faces".format(len(groups),fcs))

# Work through the candidate hash/file list...
logmsg("checking {} candidate files to find new faces..".format(len(candidates)))
print("File -> [face(s)] matched during this run:")
cnt = 0
fcs = 0
unk = 0
swp = 0
rld = False
thresh = float(cfg['threshold'])
for hash in candidates:
    # resource monitoring - if we stat seeing swapping, we re-load to ditch leaked RAM (thanks crashes in dlib!)
    res = resource.getrusage(resource.RUSAGE_SELF)
    if res[8] > swp:
        swp = res[8]
        logerr("swap increase detected: {}".format(swp))
        # TODO: rld = True
        # TODO: break
    # log progress..
    cnt += 1
    if (cnt % 100) == 0:
        db.commit()
        dirty = False
        logmsg("-- commited DB")
    if (cnt % int(cfg['report_count'])) == 0:
        logmsg("{} candidates checked, {} faces found, {} unknown..".format(cnt, fcs, unk))
    f = candidates[hash]
    try:
        # Load as image data
        pil1 = Image.open(f)
        # Skip anything with unusual aspect ratio
        asr = pil1.width/pil1.height;
        if asr<0.1 or asr>10:
            logmsg("{}: skipped, unusual aspect ratio: {}".format(f, asr))
            cur.execute('DELETE FROM file_candidates where hash = ?', (hash,))
            dirty = True
            continue
        # Extract Exif rotation (if any)
        try:
            exif = dict(pil1._getexif().items())
            if exif[274] == 3:
                pil1 = pil1.rotate(180, expand=True)
            elif exif[274] == 6:
                pil1 = pil1.rotate(270, expand=True)
            elif exif[274] == 8:
                pil1 = pil1.rotate(90, expand=True)
        except (AttributeError, KeyError, IndexError) as e:
            pass
        # Ensure RGB for remaining processing
        pil1 = pil1.convert('RGB')
        faces = []
        # Pre-filter with Tensorflow
        if tf_filter(pil1, model):
            # Resize to sane size for processing, preserve aspect ratio
            scale = 600.0 / pil1.height
            pil2 = pil1.resize(((int)(scale * pil1.width), (int)(scale * pil1.height)))
            # Convert to numpy array for face_recognition
            image2 = numpy.array(pil2)
            # Use CNN engine for accuracy, no upsampling (we've already scaled the image)
            faces = face_recognition.face_locations(image2, number_of_times_to_upsample=0, model="cnn")
        if len(faces) > 0:
            logmsg("{}: CNN found {} face(s)".format(f, len(faces)))
        # No faces, next file..
        else:
            cur.execute('DELETE FROM file_candidates where hash = ?', (hash,))
            dirty = True
            continue
        fcs += len(faces)
        # Re-scale locations to use full size image for extraction
        image1 = numpy.array(pil1)
        for i in range(0,len(faces)):
            (top, right, bottom, left) = faces[i]
            faces[i] = ((int)(top/scale),(int)(right/scale),(int)(bottom/scale),(int)(left/scale))
            logmsg("{}: face @ {},{},{},{}".format(f, faces[i][3], faces[i][0], faces[i][1], faces[i][2]))
        # Match against all groups to find closest, or none
        encs = face_recognition.face_encodings(image1, faces)
        for i in range(0,len(faces)):
            loc = faces[i]
            enc = encs[i]
            lgrp = None
            ldst = thresh
            for grp in groups:
                avg = groups[grp][0]
                if len(avg)>0:
                    # Stolen from: https://stackoverflow.com/questions/8860850/euclidean-distance-with-weights
                    d = enc - avg
                    dist = math.sqrt((weights*d*d).sum())
                    if dist < ldst:
                        ldst = dist
                        lgrp = grp
            if lgrp:
                # Found an existing group, pop it in, update average
                data = loc + (pickle.dumps(enc),hash,lgrp)
                cur.execute('INSERT INTO face_data (top,right,bottom,left,pickled,hash,grp,inpic) values (?,?,?,?,?,?,?,0)', data)
                avg = groups[lgrp][0]
                for j in range(0,len(avg)):
                    avg[j] = 0.75*avg[j] + 0.25*enc[j]
                groups[lgrp] = (avg,groups[lgrp][1])
                cur.execute('UPDATE face_groups set pickled = ? where grp = ?', (pickle.dumps(avg), lgrp))
                logmsg("{}: added to group {}".format(f, lgrp))
                print("\t{} -> {}".format(f,groups[lgrp][1]))
            else:
                # New group required
                lgrp = len(groups)
                groups[lgrp] = (enc,cfg['unknown'])
                cur.execute('INSERT OR IGNORE INTO face_labels (label) values (?)', (cfg['unknown'],))
                cur.execute('INSERT INTO face_groups (grp, pickled, label) values (?,?,?)', (lgrp, pickle.dumps(enc), cfg['unknown']))
                data = loc + (pickle.dumps(enc),hash,lgrp)
                cur.execute('INSERT INTO face_data (top,right,bottom,left,pickled,hash,grp) values (?,?,?,?,?,?,?)', data)
                logmsg("{}: created new group {}".format(f, lgrp))
                print("\t{} -> {}".format(f,groups[lgrp][1]))

    except Exception as e:
        # This is used to skip anything not an image.
        # Image.open will generate an exception if it cannot open a file.
        # Warning, this will hide other errors as well.
        err = traceback.format_exc()
        logmsg("{}: processing issue {}".format(f,err))
        # Attempt to detect crashes in dlib and reload ourselves ASAP.. before the inevitable SEGV or other fatal problem
        if "/dlib/" in err:
            rld = True
            break
        pass
    cur.execute('DELETE FROM file_candidates where hash = ?', (hash,))
    dirty = True

if dirty:
    db.commit()
db.close()
if rld:
    logmsg("reloading..")
    os.execv(sys.argv[0], sys.argv)
else:
    logmsg("stopped");
